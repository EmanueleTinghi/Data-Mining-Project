{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import _tree\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import LeaveOneGroupOut, cross_validate\n",
    "from sklearn.metrics import accuracy_score, f1_score, make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "__UTILITY FUNCTIONS__\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_to_code(tree, feature_names):\n",
    "    tree_ = tree.tree_\n",
    "    feature_name = [\n",
    "        feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
    "        for i in tree_.feature\n",
    "    ]\n",
    "    print(\"def tree({}):\".format(\", \".join(feature_names)))\n",
    "\n",
    "    def recurse(node, depth):\n",
    "        indent = \"  \" * depth\n",
    "        if tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
    "            name = feature_name[node]\n",
    "            threshold = tree_.threshold[node]\n",
    "            print(\"{}if {} <= {}:\".format(indent, name, threshold))\n",
    "            recurse(tree_.children_left[node], depth + 1)\n",
    "            print(\"{}elif {} > {}\".format(indent, name, threshold))\n",
    "            recurse(tree_.children_right[node], depth + 1)\n",
    "        else:\n",
    "            print(\"{}return {}\".format(indent, np.argmax(tree_.value[node])))\n",
    "\n",
    "    recurse(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_plot(df, var1, var2):\n",
    "    x = df[var1]\n",
    "    y = df[var2]\n",
    "    classes = df['Class']\n",
    "\n",
    "    # Mappa dei valori\n",
    "    mappa_valori = {0.0: 'Left', 1.0: 'Centered', 2.0: 'Right'}\n",
    "\n",
    "    # Sostituisci i valori nell'array\n",
    "    array_con_stringhe = np.where(np.isin(classes, list(mappa_valori.keys())), [mappa_valori[val] for val in classes], classes)\n",
    "\n",
    "    unique = list(set(array_con_stringhe))\n",
    "\n",
    "    # Assign colors based on unique values\n",
    "    colors = plt.cm.get_cmap('jet', len(unique))\n",
    "\n",
    "    for i, u in enumerate(unique):\n",
    "        xi = [x[j] for j in range(len(x)) if array_con_stringhe[j] == u]\n",
    "        yi = [y[j] for j in range(len(x)) if array_con_stringhe[j] == u]\n",
    "        plt.scatter(xi, yi, c=[colors(i)], label=str(u))\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "__DATA LOADING__\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lorenzo = pd.read_csv(\"./../../Data_unificati/lorenzo_smooth.csv\")\n",
    "Leo = pd.read_csv(\"./../../Data_unificati/leo_smooth.csv\")\n",
    "Irene = pd.read_csv(\"./../../Data_unificati/irene_smooth.csv\")\n",
    "Carlotta = pd.read_csv(\"./../../Data_unificati/carlotta_smooth.csv\")\n",
    "\n",
    "ds = pd.concat([Lorenzo, Leo, Irene, Carlotta], ignore_index=True)\n",
    "\n",
    "X = ds.drop(columns=['Class', 'Tester'])\n",
    "y = ds['Class']\n",
    "groups = ds['Tester']\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(groups.shape)\n",
    "\n",
    "print(groups.drop_duplicates())\n",
    "\n",
    "loso_cv = LeaveOneGroupOut()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "__KNN__\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_KNN = []\n",
    "for i in range(1, 201):    \n",
    "    classifier_KNN = KNeighborsClassifier(n_neighbors=6)\n",
    "    scaler = RobustScaler()\n",
    "    feat_sel = SelectKBest(k=2)\n",
    "\n",
    "    estimators_KNN = [('scaling', scaler), ('feature-selection', feat_sel), ('clf', classifier_KNN)]\n",
    "    pipe_KNN = Pipeline(estimators_KNN)\n",
    "\n",
    "    scores_KNN = cross_validate(pipe_KNN,\n",
    "                                X,\n",
    "                                y,\n",
    "                                return_estimator=True,\n",
    "                                cv=loso_cv,\n",
    "                                n_jobs=-1,\n",
    "                                groups=groups,\n",
    "                                error_score=\"raise\",\n",
    "                                scoring={'fscore': make_scorer(f1_score, average='weighted'),\n",
    "                                            'accuracy': make_scorer(accuracy_score)}\n",
    "                                )\n",
    "    results_KNN.append(pd.DataFrame(scores_KNN))\n",
    "\n",
    "# Concatenate results outside the loop\n",
    "final_results_KNN = pd.concat(results_KNN, ignore_index=True)\n",
    "\n",
    "print(final_results_KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "__RANDOM FOREST__\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_RF = []  # List to store results\n",
    "\n",
    "for i in range(1, 201):\n",
    "    classifier_RF = RandomForestClassifier(n_estimators=61, min_samples_split=30, min_samples_leaf=1, max_features='sqrt', bootstrap=True, max_depth=10, random_state=i)\n",
    "    scaler = RobustScaler()\n",
    "    feat_sel = SelectKBest(k=2)\n",
    "    estimators_RF = [('scaling', scaler), ('feature-selection', feat_sel), ('clf', classifier_RF)]\n",
    "    pipe_RF = Pipeline(estimators_RF)\n",
    "\n",
    "    scores_RF = cross_validate(pipe_RF,\n",
    "                               X,\n",
    "                               y,\n",
    "                               return_estimator=True,\n",
    "                               cv=loso_cv,\n",
    "                               n_jobs=-1,\n",
    "                               groups=groups,\n",
    "                               error_score=\"raise\",\n",
    "                               scoring={'fscore': make_scorer(f1_score, average='weighted'),\n",
    "                                        'accuracy': make_scorer(accuracy_score)}\n",
    "                               )\n",
    "    \n",
    "    results_RF.append(pd.DataFrame(scores_RF))\n",
    "\n",
    "# Concatenate results outside the loop\n",
    "final_results_RF = pd.concat(results_RF, ignore_index=True)\n",
    "\n",
    "print(final_results_RF)\n",
    "print(final_results_RF.iloc[final_results_RF['test_fscore'].idxmin()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "__ADABOOST__\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_AB = []\n",
    "for i in range(1,201):\n",
    "    classifier_AdaBoost = AdaBoostClassifier(estimator=RandomForestClassifier(n_estimators=61, min_samples_split=30, min_samples_leaf=1, max_features='sqrt', bootstrap=True, max_depth=10, random_state=i), n_estimators=400, random_state=i)\n",
    "    scaler = RobustScaler()\n",
    "    feat_sel = SelectKBest(k=2)\n",
    "\n",
    "    estimators_AdaBoost = [('scaling', scaler), ('feature-selection', feat_sel), ('clf', classifier_AdaBoost)]\n",
    "    pipe_AdaBoost = Pipeline(estimators_AdaBoost)\n",
    "\n",
    "    scores_AdaBoost = cross_validate(pipe_AdaBoost,\n",
    "                            X,\n",
    "                            y,\n",
    "                            return_estimator = True,\n",
    "                            cv = loso_cv,\n",
    "                            n_jobs=-1,\n",
    "                            groups=groups,\n",
    "                            error_score=\"raise\",\n",
    "                            scoring = {'fscore': make_scorer(f1_score, average='weighted'),\n",
    "                                        'accuracy': make_scorer(accuracy_score)}\n",
    "    )\n",
    "    results_AB.append(pd.DataFrame(scores_AdaBoost))\n",
    "# Concatenate results outside the loop\n",
    "final_results_AdaBoost = pd.concat(results_AB, ignore_index=True)\n",
    "print(final_results_AdaBoost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "__PERFORMANCE EVALUATION__\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame({'KNN': final_results_KNN['test_fscore'],\n",
    "                        'RF': final_results_RF['test_fscore'],\n",
    "                        'AB': final_results_AdaBoost['test_fscore']})\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "ax = metrics.boxplot(figsize = (3,3))\n",
    "ax.set_ylabel('f-score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "print(wilcoxon(metrics.RF, metrics.AB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean of RF: \" + str(np.mean(metrics.RF)))\n",
    "print(\"Mean of AB: \" + str(np.mean(metrics.AB)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "print(wilcoxon(metrics.KNN, metrics.RF))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "__TREE ANALYSIS OF ADABOOST__\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print( ds[(ds['Tester'] == 'Lorenzo')].drop(columns=['Class', 'Tester']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_AdaBoost = AdaBoostClassifier(estimator=RandomForestClassifier(n_estimators=61, min_samples_split=30, min_samples_leaf=1, max_features='sqrt', bootstrap=True, max_depth=10), n_estimators=400, random_state=0)\n",
    "scaler = RobustScaler()\n",
    "feat_sel = SelectKBest(k=2)\n",
    "\n",
    "estimators_AdaBoost = [('scaling', scaler), ('feature-selection', feat_sel), ('clf', classifier_AdaBoost)]\n",
    "pipe_AdaBoost = Pipeline(estimators_AdaBoost)\n",
    "\n",
    "X_train = ds[(ds['Tester'] != 'Lorenzo')].drop(columns=['Class', 'Tester'])\n",
    "X_test= ds[(ds['Tester'] == 'Lorenzo')].drop(columns=['Class', 'Tester'])\n",
    "\n",
    "y_train = ds[(ds['Tester'] != 'Lorenzo')]['Class']\n",
    "y_test= ds[(ds['Tester'] == 'Lorenzo')]['Class']\n",
    "\n",
    "pipe_AdaBoost.fit(X_train, y_train)\n",
    "y_pred = pipe_AdaBoost.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_pred, y_test))\n",
    "\n",
    "#the selected k=2 best feature chosen by the model\n",
    "print(X.columns[pipe_AdaBoost['feature-selection'].get_support()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def tree(meanFreq_MaxS11, mean_S11DEG):\n",
      "  if meanFreq_MaxS11 <= 0.15777262393385172:\n",
      "    if mean_S11DEG <= 0.1628556177020073:\n",
      "      return 1\n",
      "    elif mean_S11DEG > 0.1628556177020073\n",
      "      if meanFreq_MaxS11 <= -1.5672853589057922:\n",
      "        return 0\n",
      "      elif meanFreq_MaxS11 > -1.5672853589057922\n",
      "        return 0\n",
      "  elif meanFreq_MaxS11 > 0.15777262393385172\n",
      "    if meanFreq_MaxS11 <= 0.76450115442276:\n",
      "      if meanFreq_MaxS11 <= 0.30162413418293:\n",
      "        return 2\n",
      "      elif meanFreq_MaxS11 > 0.30162413418293\n",
      "        return 2\n",
      "    elif meanFreq_MaxS11 > 0.76450115442276\n",
      "      if meanFreq_MaxS11 <= 0.8689095079898834:\n",
      "        return 1\n",
      "      elif meanFreq_MaxS11 > 0.8689095079898834\n",
      "        return 1\n"
     ]
    }
   ],
   "source": [
    "tree_to_code(pipe_AdaBoost['clf'].estimators_[0].estimators_[1], X.columns[pipe_AdaBoost['feature-selection'].get_support()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_plot(ds[(ds['Tester'] == 'Lorenzo')], 'meanFreq_MaxS11', 'meanFreq_MaxS22')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
