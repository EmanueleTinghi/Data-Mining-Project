{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import LeaveOneGroupOut, cross_validate\n",
    "from sklearn.metrics import accuracy_score, f1_score, make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "__PREPARATORY CODE CELLS__\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the datasets\n",
    "Lorenzo = pd.read_csv(\"./../Dati_unificati/lorenzo_smooth.csv\")\n",
    "Leo = pd.read_csv(\"./../Dati_unificati/leo_smooth.csv\")\n",
    "Irene = pd.read_csv(\"./../Dati_unificati/irene_smooth.csv\")\n",
    "Carlotta = pd.read_csv(\"./../Dati_unificati/carlotta_smooth.csv\")\n",
    "\n",
    "ds = pd.concat([Lorenzo, Leo, Irene, Carlotta], ignore_index=True)\n",
    "\n",
    "X = ds.drop(columns=['Class', 'Tester'])\n",
    "y = ds['Class']\n",
    "groups = ds['Tester']\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(groups.shape)\n",
    "\n",
    "print(groups.drop_duplicates())\n",
    "\n",
    "loso_cv = LeaveOneGroupOut()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testers order\n",
    "for train, test in loso_cv.split(X,y,groups):\n",
    "    if (test[0] == 0):\n",
    "        print(\"Lorenzo\")\n",
    "    elif (test[0] == 272):\n",
    "        print('Leo')\n",
    "    elif (test[0] == 450):\n",
    "        print(\"Irene\")\n",
    "    elif (test[0] == 635):\n",
    "        print('Carlotta')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "__KNN__\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search for the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "results = pd.DataFrame(columns=['X', 'Mean', 'Min', 'Max'])\n",
    "\n",
    "#Search between 1 nearest neighbor and 80 nearest neighbor\n",
    "for n in range(1, 80):\n",
    "    #Pipeline parameters\n",
    "    classifier_KNN = KNeighborsClassifier(n_neighbors=n)\n",
    "    scaler = RobustScaler()\n",
    "    feat_sel = SelectKBest(k=2)\n",
    "\n",
    "    estimators_KNN = [('scaling', scaler), ('feature-selection', feat_sel), ('clf', classifier_KNN)]\n",
    "    pipe_KNN = Pipeline(estimators_KNN)\n",
    "\n",
    "    #Cross validation with leave-one-subject-out\n",
    "    scores_KNN = cross_validate(pipe_KNN,\n",
    "                                X,\n",
    "                                y,\n",
    "                                return_estimator=True,\n",
    "                                cv=loso_cv,\n",
    "                                n_jobs=-1,\n",
    "                                groups=groups,\n",
    "                                error_score=\"raise\",\n",
    "                                scoring={'fscore': make_scorer(f1_score, average='weighted'),\n",
    "                                         'accuracy': make_scorer(accuracy_score)}\n",
    "                                )\n",
    "\n",
    "    # Concatenate the new values as a DataFrame and append to the existing results\n",
    "    new_row = pd.DataFrame({\n",
    "        'X': [n],\n",
    "        'Mean': [np.mean(scores_KNN['test_fscore'])],\n",
    "        'Min': [np.min(scores_KNN['test_fscore'])],\n",
    "        'Max': [np.max(scores_KNN['test_fscore'])]\n",
    "    })\n",
    "    results = pd.concat([results, new_row], ignore_index=True)\n",
    "\n",
    "# Find the index of the maximum mean F-score\n",
    "max_mean_index = results['Mean'].idxmax()\n",
    "\n",
    "# Find the index of the minimum and maximum F-score in the other two plots\n",
    "min_index = results['Min'].idxmin()\n",
    "max_index = results['Max'].idxmax()\n",
    "\n",
    "# Plot the mean F-score\n",
    "plt.plot(results['X'], results['Mean'], color='blue', linewidth=2, label='Mean F-score')\n",
    "\n",
    "# Highlight the point of maximum mean F-score\n",
    "plt.scatter(results['X'][max_mean_index], results['Mean'][max_mean_index], color='red', marker='*', s=100)\n",
    "plt.annotate(f'Max Mean F-score ({results[\"Mean\"][max_mean_index]:.3f})\\nNeighbors: {results[\"X\"][max_mean_index]:.3f}',\n",
    "             (results['X'][max_mean_index], results['Mean'][max_mean_index]),\n",
    "             textcoords=\"offset points\",\n",
    "             xytext=(0,10),\n",
    "             ha='center',\n",
    "             color='red')\n",
    "\n",
    "# Plot the minimum F-score\n",
    "plt.plot(results['X'], results['Min'], color='orange', linewidth=2, linestyle='--', label='Min F-score')\n",
    "\n",
    "# Plot the maximum F-score\n",
    "plt.plot(results['X'], results['Max'], color='green', linewidth=2, linestyle='--', label='Max F-score')\n",
    "\n",
    "# Highlight the point of minimum F-score corresponding to max_mean_index\n",
    "plt.scatter(results['X'][max_mean_index], results['Min'][max_mean_index], color='brown', marker='*', s=100)\n",
    "plt.annotate(f'Corresponding Min F-score\\n({results[\"Min\"][max_mean_index]:.3f})',\n",
    "             (results['X'][max_mean_index], results['Min'][max_mean_index]),\n",
    "             textcoords=\"offset points\",\n",
    "             xytext=(0,10),\n",
    "             ha='center',\n",
    "             color='brown')\n",
    "\n",
    "\n",
    "# Highlight the point of maximum F-score corresponding to max_mean_index\n",
    "plt.scatter(results['X'][max_mean_index], results['Max'][max_mean_index], color='purple', marker='*', s=100)\n",
    "plt.annotate(f'Corresponding Max F-score\\n({results[\"Max\"][max_mean_index]:.3f})',\n",
    "             (results['X'][max_mean_index], results['Max'][max_mean_index]),\n",
    "             textcoords=\"offset points\",\n",
    "             xytext=(0, -30),\n",
    "             ha='center',\n",
    "             color='purple')\n",
    "\n",
    "plt.xlabel('Number of Neighbors')\n",
    "plt.ylabel('F-score')\n",
    "plt.legend()\n",
    "plt.title('F-score Statistics for Different Numbers of Neighbors')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_KNN = KNeighborsClassifier(n_neighbors=6)\n",
    "scaler = RobustScaler()\n",
    "feat_sel = SelectKBest(k=2)\n",
    "\n",
    "estimators_KNN = [('scaling', scaler), ('feature-selection', feat_sel), ('clf', classifier_KNN)]\n",
    "pipe_KNN = Pipeline(estimators_KNN)\n",
    "\n",
    "scores_KNN = cross_validate(pipe_KNN,\n",
    "                            X,\n",
    "                            y,\n",
    "                            return_estimator=True,\n",
    "                            cv=loso_cv,\n",
    "                            n_jobs=-1,\n",
    "                            groups=groups,\n",
    "                            error_score=\"raise\",\n",
    "                            scoring={'fscore': make_scorer(f1_score, average='weighted'),\n",
    "                                        'accuracy': make_scorer(accuracy_score)}\n",
    "                            )\n",
    "\n",
    "print(scores_KNN)\n",
    "print(np.mean(scores_KNN['test_fscore']))\n",
    "print(np.mean(scores_KNN['test_accuracy']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Dataset senza smoothing__: \n",
    "    * __F-score (AVG: 0.609)__: \n",
    "        + 0.82418721\n",
    "        + 0.5358844 \n",
    "        + 0.50821999        \n",
    "        + 0.57001965\n",
    "    * __Accuracy (AVG: 0.694)__:\n",
    "        + 0.83261803\n",
    "        + 0.65405405\n",
    "        + 0.62921348\n",
    "        + 0.66176471\n",
    "\n",
    "-  __Dataset con smoothing__: \n",
    "    * __F-score (AVG: 0.724)__:\n",
    "        + 0.78116751\n",
    "        + 0.5358844\n",
    "        + 1\n",
    "        + 0.57844139\n",
    "    * __Accuracy (AVG: 0.774)__: \n",
    "        + 0.78969957\n",
    "        + 0.65405405\n",
    "        + 1\n",
    "        + 0.65073529"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "__RANDOM FOREST__\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search for the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame(columns=['X', 'Mean', 'Min', 'Max'])\n",
    "\n",
    "#iterate over min_sample_leaf\n",
    "for n in range(1, 10):\n",
    "    #iterate over min_samples_split\n",
    "    for m in range(1, 50):\n",
    "        #iterate over n_estimators\n",
    "        for e in range(1, 500, 20):\n",
    "            classifier_RF = RandomForestClassifier(n_estimators=e, min_samples_split=m, min_samples_leaf=n, max_features='sqrt', bootstrap=True, max_depth=10)\n",
    "            scaler = RobustScaler()\n",
    "            feat_sel = SelectKBest(k=2)\n",
    "            estimators_RF = [('scaling', scaler), ('feature-selection', feat_sel), ('clf', classifier_RF)]\n",
    "            pipe_RF = Pipeline(estimators_RF)\n",
    "\n",
    "            scores_RF = cross_validate(pipe_RF,\n",
    "                                    X,\n",
    "                                    y,\n",
    "                                    return_estimator=True,\n",
    "                                    cv=loso_cv,\n",
    "                                    n_jobs=-1,\n",
    "                                    groups=groups,\n",
    "                                    error_score=\"raise\",\n",
    "                                    scoring={'fscore': make_scorer(f1_score, average='weighted'),\n",
    "                                                'accuracy': make_scorer(accuracy_score)}\n",
    "                                    )\n",
    "\n",
    "            # Concatenate the new values as a DataFrame and append to the existing results\n",
    "            new_row = pd.DataFrame({'X': [str(m) + '-' + str(n) + '-' + str(e)],\n",
    "                                    'Mean': [np.mean(scores_RF['test_fscore'])],\n",
    "                                    'Min': [np.min(scores_RF['test_fscore'])],\n",
    "                                    'Max': [np.max(scores_RF['test_fscore'])]})\n",
    "            \n",
    "            results = pd.concat([results, new_row], ignore_index=True)\n",
    "\n",
    "    print(n)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X         41-2-1\n",
      "Mean    0.788409\n",
      "Min     0.535884\n",
      "Max          1.0\n",
      "Name: 180, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Find the index of the maximum mean F-score\n",
    "max_mean_index = results['Mean'].idxmax()\n",
    "\n",
    "print(results.iloc[max_mean_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_RF = RandomForestClassifier(n_estimators=61, min_samples_split=30, min_samples_leaf=1, max_features='sqrt', bootstrap=True, max_depth=10)\n",
    "scaler = RobustScaler()\n",
    "feat_sel = SelectKBest(k=2)\n",
    "estimators_RF = [('scaling', scaler), ('feature-selection', feat_sel), ('clf', classifier_RF)]\n",
    "pipe_RF = Pipeline(estimators_RF)\n",
    "\n",
    "scores_RF = cross_validate(pipe_RF,\n",
    "                        X,\n",
    "                        y,\n",
    "                        return_estimator=True,\n",
    "                        cv=loso_cv,\n",
    "                        n_jobs=-1,\n",
    "                        groups=groups,\n",
    "                        error_score=\"raise\",\n",
    "                        scoring={'fscore': make_scorer(f1_score, average='weighted'),\n",
    "                                    'accuracy': make_scorer(accuracy_score)}\n",
    "                        )\n",
    "\n",
    "print(scores_RF)\n",
    "print(np.mean(scores_RF['test_fscore']))\n",
    "print(np.mean(scores_RF['test_accuracy']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Dataset senza smoothing__: \n",
    "    * __F-score (AVG: 0.636)__: \n",
    "        + 0.58946152\n",
    "        + 0.54697555\n",
    "        + 1        \n",
    "        + 0.40744893\n",
    "    * __Accuracy (AVG: 0.708)__:\n",
    "        + 0.68669528\n",
    "        + 0.65405405\n",
    "        + 1\n",
    "        + 0.49264706\n",
    "\n",
    "-  __Dataset con smoothing__: \n",
    "    * __F-score (AVG: 0.745)__:\n",
    "        + 1\n",
    "        + 0.5358844\n",
    "        + 0.92478368\n",
    "        + 0.52102544\n",
    "    * __Accuracy (AVG: 0.783)__: \n",
    "        + 1\n",
    "        + 0.65405405\n",
    "        + 0.92696629\n",
    "        + 0.55147059 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "__ADABOOST__\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_AdaBoost = AdaBoostClassifier(estimator=RandomForestClassifier(n_estimators=61, min_samples_split=30, min_samples_leaf=1, max_features='sqrt', bootstrap=True, max_depth=10), n_estimators=400, random_state=5)\n",
    "scaler = RobustScaler()\n",
    "feat_sel = SelectKBest(k=2)\n",
    "\n",
    "estimators_AdaBoost = [('scaling', scaler), ('feature-selection', feat_sel), ('clf', classifier_AdaBoost)]\n",
    "pipe_AdaBoost = Pipeline(estimators_AdaBoost)\n",
    "\n",
    "scores_AdaBoost = cross_validate(pipe_AdaBoost,\n",
    "                         X,\n",
    "                         y,\n",
    "                         return_estimator = True,\n",
    "                         cv = loso_cv,\n",
    "                         n_jobs=-1,\n",
    "                         groups=groups,\n",
    "                         error_score=\"raise\",\n",
    "                         scoring = {'fscore': make_scorer(f1_score, average='weighted'),\n",
    "                                    'accuracy': make_scorer(accuracy_score)}\n",
    ")\n",
    "\n",
    "print(scores_AdaBoost)\n",
    "print(np.mean(scores_AdaBoost['test_fscore']))\n",
    "print(np.mean(scores_AdaBoost['test_accuracy']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Dataset senza smoothing__: \n",
    "    * __F-score (AVG: 0.637)__: \n",
    "        + 0.58946152 \n",
    "        + 0.54697555 \n",
    "        + 1        \n",
    "        + 0.41180283\n",
    "    * __Accuracy (AVG: 0.709)__:\n",
    "        + 0.68669528\n",
    "        + 0.65405405\n",
    "        + 1\n",
    "        + 0.49632353\n",
    "\n",
    "-  __Dataset con smoothing__: \n",
    "    * __F-score (AVG: 0.748)__:\n",
    "        + 1\n",
    "        + 0.54697555\n",
    "        + 0.92478368\n",
    "        + 0.52102544\n",
    "    * __Accuracy (AVG: 0.783)__: \n",
    "        + 1\n",
    "        + 0.65405405\n",
    "        + 0.92696629\n",
    "        + 0.55147059"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "__OTHER TESTED MODELS WITH WORSE PERFORMANCE__\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "__SVC__\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "powers_of_10 = [-3, -2, -1, 1, 2, 3]  # corresponding to 0.001, 0.01, 0.1, 1, 10, 100, 1000\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "results = pd.DataFrame(columns=['X', 'Mean', 'Min', 'Max'])\n",
    "\n",
    "for power in powers_of_10:\n",
    "    C_value = 10 ** power\n",
    "    \n",
    "    # Create an instance of the Support Vector Classification (SVC) with your desired parameters\n",
    "    classifier_SVC = SVC(kernel='rbf', C=C_value)\n",
    "\n",
    "    # Other parts of the code remain the same\n",
    "    scaler = RobustScaler()\n",
    "    feat_sel = SelectKBest(k=2)\n",
    "\n",
    "    # Use the SVC classifier in the pipeline\n",
    "    estimators_SVC = [('scaling', scaler), ('feature-selection', feat_sel), ('clf', classifier_SVC)]\n",
    "    pipe_SVC = Pipeline(estimators_SVC)\n",
    "\n",
    "    # Assuming X, y, loso_cv, and groups are defined before this point\n",
    "\n",
    "    # Perform cross-validation using Leave-One-Group-Out (LOSO) strategy\n",
    "    scores_SVC = cross_validate(pipe_SVC,\n",
    "                                X,\n",
    "                                y,\n",
    "                                return_estimator=True,\n",
    "                                cv=LeaveOneGroupOut(),\n",
    "                                n_jobs=-1,\n",
    "                                groups=groups,\n",
    "                                error_score=\"raise\",\n",
    "                                scoring={'fscore': make_scorer(f1_score, average='weighted'),\n",
    "                                        'accuracy': make_scorer(accuracy_score)}\n",
    "                                )\n",
    "        # Concatenate the new values as a DataFrame and append to the existing results\n",
    "    new_row = pd.DataFrame({\n",
    "        'X': [power],\n",
    "        'Mean': [np.mean(scores_SVC['test_fscore'])],\n",
    "        'Min': [np.min(scores_SVC['test_fscore'])],\n",
    "        'Max': [np.max(scores_SVC['test_fscore'])]\n",
    "    })\n",
    "\n",
    "    results = pd.concat([results, new_row], ignore_index=True)\n",
    "\n",
    "# Find the index of the maximum mean F-score\n",
    "max_mean_index = results['Mean'].idxmax()\n",
    "\n",
    "# Find the index of the minimum and maximum F-score in the other two plots\n",
    "min_index = results['Min'].idxmin()\n",
    "max_index = results['Max'].idxmax()\n",
    "\n",
    "# Plot the mean F-score\n",
    "plt.plot(results['X'], results['Mean'], color='blue', linewidth=2, label='Mean F-score')\n",
    "\n",
    "# Highlight the point of maximum mean F-score\n",
    "plt.scatter(results['X'][max_mean_index], results['Mean'][max_mean_index], color='red', marker='*', s=100)\n",
    "plt.annotate(f'Max Mean F-score ({results[\"Mean\"][max_mean_index]:.3f})\\nValue of C: {results[\"X\"][max_mean_index]:.3f}',\n",
    "             (results['X'][max_mean_index], results['Mean'][max_mean_index]),\n",
    "             textcoords=\"offset points\",\n",
    "             xytext=(0,10),\n",
    "             ha='center',\n",
    "             color='red')\n",
    "\n",
    "# Plot the minimum F-score\n",
    "plt.plot(results['X'], results['Min'], color='orange', linewidth=2, linestyle='--', label='Min F-score')\n",
    "\n",
    "# Plot the maximum F-score\n",
    "plt.plot(results['X'], results['Max'], color='green', linewidth=2, linestyle='--', label='Max F-score')\n",
    "\n",
    "# Highlight the point of minimum F-score\n",
    "plt.scatter(results['X'][max_mean_index], results['Min'][max_mean_index], color='brown', marker='*', s=100)\n",
    "plt.annotate(f'Corresponding Min F-score\\n({results[\"Min\"][max_mean_index]:.3f})',\n",
    "             (results['X'][max_mean_index], results['Min'][max_mean_index]),\n",
    "             textcoords=\"offset points\",\n",
    "             xytext=(0,10),\n",
    "             ha='center',\n",
    "             color='brown')\n",
    "\n",
    "\n",
    "# Highlight the point of maximum F-score\n",
    "plt.scatter(results['X'][max_mean_index], results['Max'][max_mean_index], color='purple', marker='*', s=100)\n",
    "plt.annotate(f'Corresponding Max F-score\\n({results[\"Max\"][max_mean_index]:.3f})',\n",
    "             (results['X'][max_mean_index], results['Max'][max_mean_index]),\n",
    "             textcoords=\"offset points\",\n",
    "             xytext=(0, -30),\n",
    "             ha='center',\n",
    "             color='purple')\n",
    "\n",
    "plt.xlabel('Value of C')\n",
    "plt.ylabel('F-score')\n",
    "plt.legend()\n",
    "plt.title('F-score Statistics for Different C')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_SVC = SVC(kernel='rbf', C=0.1)\n",
    "\n",
    "# Other parts of the code remain the same\n",
    "scaler = RobustScaler(quantile_range=(25, 75))\n",
    "feat_sel = SelectKBest(k=2)\n",
    "\n",
    "# Use the SVC classifier in the pipeline\n",
    "estimators_SVC = [('scaling', scaler), ('feature-selection', feat_sel), ('clf', classifier_SVC)]\n",
    "pipe_SVC = Pipeline(estimators_SVC)\n",
    "\n",
    "# Assuming X, y, loso_cv, and groups are defined before this point\n",
    "\n",
    "# Perform cross-validation using Leave-One-Group-Out (LOSO) strategy\n",
    "scores_SVC = cross_validate(pipe_SVC,\n",
    "                            X,\n",
    "                            y,\n",
    "                            return_estimator=True,\n",
    "                            cv=LeaveOneGroupOut(),\n",
    "                            n_jobs=-1,\n",
    "                            groups=groups,\n",
    "                            error_score=\"raise\",\n",
    "                            scoring={'fscore': make_scorer(f1_score, average='weighted'),\n",
    "                                    'accuracy': make_scorer(accuracy_score)}\n",
    "                            )\n",
    "\n",
    "print(scores_SVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Dataset senza smoothing__: \n",
    "    * __F-score (AVG: 0.660)__: \n",
    "        + 0.52911271\n",
    "        + 0.5358844\n",
    "        + 1       \n",
    "        + 0.57587227\n",
    "    * __Accuracy (AVG: 0.741)__:\n",
    "        + 0.64377682\n",
    "        + 0.65405405\n",
    "        + 1\n",
    "        + 0.66911765\n",
    "\n",
    "-  __Dataset con smoothing__: \n",
    "    * __F-score (AVG: 0.650)__:\n",
    "        + 0.52911271\n",
    "        + 0.5358844\n",
    "        + 1\n",
    "        + 0.53681049\n",
    "    * __Accuracy (AVG: 0.731)__: \n",
    "        + 0.64377682\n",
    "        + 0.65405405\n",
    "        + 1\n",
    "        + 0.62867647"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "__Gradient Boosting__\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "results = pd.DataFrame(columns=['X', 'Mean', 'Min', 'Max'])\n",
    "\n",
    "for i in range(1, 50, 1):\n",
    "    # Create an instance of the Gradient Boosting Classifier with desired parameters\n",
    "    classifier_GB = GradientBoostingClassifier(n_estimators=20, learning_rate=0.1, max_depth=i)\n",
    "\n",
    "    # Other parts of the code remain the same\n",
    "    scaler = RobustScaler()\n",
    "    feat_sel = SelectKBest(k=2)\n",
    "\n",
    "    # Use the Gradient Boosting classifier in the pipeline\n",
    "    estimators_GB = [('scaling', scaler), ('feature-selection', feat_sel), ('clf', classifier_GB)]\n",
    "    pipe_GB = Pipeline(estimators_GB)\n",
    "\n",
    "    # Assuming X, y, loso_cv, and groups are defined before this point\n",
    "\n",
    "    # Perform cross-validation using Leave-One-Group-Out (LOSO) strategy\n",
    "    scores_GB = cross_validate(pipe_GB,\n",
    "                            X,\n",
    "                            y,\n",
    "                            return_estimator=True,\n",
    "                            cv=LeaveOneGroupOut(),\n",
    "                            n_jobs=-1,\n",
    "                            groups=groups,\n",
    "                            error_score=\"raise\",\n",
    "                            scoring={'fscore': make_scorer(f1_score, average='weighted'),\n",
    "                                        'accuracy': make_scorer(accuracy_score)}\n",
    "                            )\n",
    "\n",
    "    new_row = pd.DataFrame({\n",
    "        'X': [i],\n",
    "        'Mean': [np.mean(scores_SVC['test_fscore'])],\n",
    "        'Min': [np.min(scores_SVC['test_fscore'])],\n",
    "        'Max': [np.max(scores_SVC['test_fscore'])]\n",
    "    })\n",
    "\n",
    "    results = pd.concat([results, new_row], ignore_index=True)\n",
    "\n",
    "print(scores_GB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Dataset senza smoothing__: \n",
    "    * __F-score (AVG: 0.643)__: \n",
    "        + 0.34773977\n",
    "        + 1\n",
    "        + 0.6172367        \n",
    "        + 0.60698666\n",
    "    * __Accuracy (AVG: 0.716)__:\n",
    "        + 0.43347639\n",
    "        + 1\n",
    "        + 0.71910112\n",
    "        + 0.70955882\n",
    "\n",
    "-  __Dataset con smoothing__: \n",
    "    * __F-score (AVG: 0.650)__:\n",
    "        + 0.52911271\n",
    "        + 0.5358844\n",
    "        + 1\n",
    "        + 0.53681049\n",
    "    * __Accuracy (AVG: 0.731)__: \n",
    "        + 0.64377682\n",
    "        + 0.65405405\n",
    "        + 1\n",
    "        + 0.62867647"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "__SGD__\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the SGD Classifier with desired parameters\n",
    "classifier_SGD = SGDClassifier(loss='hinge', alpha=0.0001, max_iter=1000, random_state=42)\n",
    "\n",
    "# Other parts of the code remain the same\n",
    "scaler = RobustScaler()\n",
    "feat_sel = SelectKBest(k=2)\n",
    "\n",
    "# Use the SGD classifier in the pipeline\n",
    "estimators_SGD = [('scaling', scaler), ('feature-selection', feat_sel), ('clf', classifier_SGD)]\n",
    "pipe_SGD = Pipeline(estimators_SGD)\n",
    "\n",
    "# Assuming X, y, loso_cv, and groups are defined before this point\n",
    "\n",
    "# Perform cross-validation using Leave-One-Group-Out (LOSO) strategy\n",
    "scores_SGD = cross_validate(pipe_SGD,\n",
    "                            X,\n",
    "                            y,\n",
    "                            return_estimator=True,\n",
    "                            cv=LeaveOneGroupOut(),\n",
    "                            n_jobs=-1,\n",
    "                            groups=groups,\n",
    "                            error_score=\"raise\",\n",
    "                            scoring={'fscore': make_scorer(f1_score, average='weighted'),\n",
    "                                     'accuracy': make_scorer(accuracy_score)}\n",
    "                            )\n",
    "\n",
    "print(scores_SGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Dataset senza smoothing__: \n",
    "    * __F-score (AVG: 0.645)__: \n",
    "        + 0.52911271\n",
    "        + 1\n",
    "        + 0.50821999\n",
    "        + 0.54167635\n",
    "    * __Accuracy (AVG: 0.731)__:\n",
    "        + 0.64377682\n",
    "        + 1\n",
    "        + 0.62921348\n",
    "        + 0.65073529\n",
    "\n",
    "-  __Dataset con smoothing__: \n",
    "    * __F-score (AVG: 0.618)__:\n",
    "        + 0.52911271\n",
    "        + 1\n",
    "        + 0.50821999\n",
    "        + 0.43330882\n",
    "    * __Accuracy (AVG: 0.704)__: \n",
    "        + 0.64377682\n",
    "        + 1\n",
    "        + 0.62921348\n",
    "        + 0.54411765"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "__SGD with RBFSampler__\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the SGD Classifier with desired parameters\n",
    "classifier_SGD = SGDClassifier(loss='hinge', alpha=0.0001, max_iter=1000, random_state=42)\n",
    "\n",
    "# Use RBFSampler with SGD Classifier\n",
    "rbf_sampler = RBFSampler(gamma=0.5, n_components=100, random_state=42)\n",
    "\n",
    "# Other parts of the code remain the same\n",
    "scaler = RobustScaler()\n",
    "feat_sel = SelectKBest(k=2)\n",
    "\n",
    "# Use the SGD classifier with RBFSampler in the pipeline\n",
    "estimators_SGD_rbf = [('scaling', scaler), ('feature-selection', feat_sel), ('rbf-sampler', rbf_sampler), ('clf', classifier_SGD)]\n",
    "pipe_SGD_rbf = Pipeline(estimators_SGD_rbf)\n",
    "\n",
    "# Assuming X, y, loso_cv, and groups are defined before this point\n",
    "\n",
    "# Perform cross-validation using Leave-One-Group-Out (LOSO) strategy\n",
    "scores_SGD_rbf = cross_validate(pipe_SGD_rbf,\n",
    "                                X,\n",
    "                                y,\n",
    "                                return_estimator=True,\n",
    "                                cv=LeaveOneGroupOut(),\n",
    "                                n_jobs=-1,\n",
    "                                groups=groups,\n",
    "                                error_score=\"raise\",\n",
    "                                scoring={'fscore': make_scorer(f1_score, average='weighted'),\n",
    "                                         'accuracy': make_scorer(accuracy_score)}\n",
    "                                )\n",
    "\n",
    "print(scores_SGD_rbf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Dataset senza smoothing__: \n",
    "    * __F-score (AVG: 0.635)__: \n",
    "        + 0.52911271\n",
    "        + 0.5358844\n",
    "        + 0.90904965        \n",
    "        + 0.56706786\n",
    "    * __Accuracy (AVG: 0.717)__:\n",
    "        + 0.64377682\n",
    "        + 0.65405405\n",
    "        + 0.91011236\n",
    "        + 0.65808824\n",
    "\n",
    "-  __Dataset con smoothing__: \n",
    "    * __F-score (AVG: 0.564)__:\n",
    "        + 0.49429745\n",
    "        + 0.5358844\n",
    "        + 0.65607763\n",
    "        + 0.56881985\n",
    "    * __Accuracy (AVG: 0.655)__: \n",
    "        + 0.59656652\n",
    "        + 0.65405405\n",
    "        + 0.70786517\n",
    "        + 0.66176471"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
