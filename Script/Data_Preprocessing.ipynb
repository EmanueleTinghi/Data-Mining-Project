{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from pandas.plotting import scatter_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "__UTILITY FUNCTIONS__\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path, smoothing_present = True):\n",
    "    intermediate = pd.DataFrame()\n",
    "    data = pd.DataFrame()\n",
    "    freq_scale = 1000000 #the frequencies as scaled by a factor 10^(6)\n",
    "    rows_to_skip = 6\n",
    "    i = 0\n",
    "    span = 20   #window size for the smoothing\n",
    "    number_of_files = len(os.listdir(path))\n",
    "\n",
    "    #iterate over the files in the folder\n",
    "    for i in range(1, number_of_files+1):\n",
    "        if os.path.exists(path + f\"/Data ({i}).csv\"):\n",
    "            df = pd.read_csv(path + f\"/Data ({i}).csv\", skiprows=rows_to_skip)\n",
    "\n",
    "        #smoothing \n",
    "        if(smoothing_present):\n",
    "            df['S11(DB)'] = df['S11(DB)'].ewm(span=span, adjust=False).mean()\n",
    "            df['S22(DB)'] = df['S22(DB)'].ewm(span=span, adjust=False).mean()\n",
    "            df['S11(DEG)'] = df['S11(DEG)'].ewm(span=span, adjust=False).mean()\n",
    "            df['S22(DEG)'] = df['S22(DEG)'].ewm(span=span, adjust=False).mean()\n",
    "\n",
    "        #exctract the rows with maximum values both of S11(DB) and S22(DB)\n",
    "        row_maxS11 = df.loc[df['S11(DB)'].abs().idxmax()]\n",
    "        row_maxS22 = df.loc[df['S22(DB)'].abs().idxmax()]\n",
    "\n",
    "        #create a dataframe with the values of phase and frequency corresponding to the previus rows\n",
    "        intermediate = pd.DataFrame([(pd.to_numeric(row_maxS11['Freq(Hz)'])/freq_scale), row_maxS11['S11(DB)'], row_maxS11['S11(DEG)'], (pd.to_numeric(row_maxS22['Freq(Hz)'])/freq_scale), \n",
    "                        row_maxS22['S22(DB)'], row_maxS22['S22(DEG)']])\n",
    "        \n",
    "        data = pd.concat([data, intermediate.T], ignore_index=True)\n",
    "\n",
    "    column_names = ['Freq(Hz)S11', 'S11(DB)', 'S11(DEG)', 'Freq(Hz)S22', 'S22(DB)', 'S22(DEG)']\n",
    "    data.columns = column_names\n",
    "    print(data.shape)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#values of cls = 0 (Left), cls = 1 (center), cls = 2 (Right)\n",
    "#weights of the testers = 60 (Irene), 70 (Carlotta), 80 (Leo), 90 (Lorenzo)\n",
    "def calculate_window_information(dataset, window_size = 50, weight=-1, step_size = 20, instances_to_skip = 150, cls=-1):\n",
    "    windowed_dataset = pd.DataFrame()\n",
    "    iterator = dataset.iterrows()\n",
    "\n",
    "    for i, rows in iterator:\n",
    "        #consider only the windows that must be calculated (due to the window size or the removal of the initial or final instances)\n",
    "        if (i < (window_size - 1)) | (i < instances_to_skip) | (i > (len(dataset) - instances_to_skip)):\n",
    "            continue\n",
    "\n",
    "        #calculate the means\n",
    "        meanFreq_MaxS11 = pd.to_numeric(dataset['Freq(Hz)S11'].iloc[i-(window_size - 1): i]).mean()\n",
    "        mean_MaxS11 = dataset['S11(DB)'].iloc[i-(window_size - 1): i].mean()\n",
    "        mean_S11DEG = dataset['S11(DEG)'].iloc[i-(window_size - 1): i].mean()\n",
    "\n",
    "        meanFreq_MaxS22 = pd.to_numeric(dataset['Freq(Hz)S22'].iloc[i-(window_size - 1): i]).mean()\n",
    "        mean_MaxS22 = dataset['S22(DB)'].iloc[i-(window_size - 1): i].mean()\n",
    "        mean_S22DEG = dataset['S22(DEG)'].iloc[i-(window_size - 1): i].mean()\n",
    "\n",
    "        #calculate the variances\n",
    "        varFreq_MaxS11 = np.var(pd.to_numeric(dataset['Freq(Hz)S11'].iloc[i-(window_size - 1): i]))\n",
    "        var_MaxS11 = np.var(dataset['S11(DB)'].iloc[i-(window_size - 1): i])\n",
    "        var_S11DEG = np.var(dataset['S11(DEG)'].iloc[i-(window_size - 1): i])\n",
    "\n",
    "        varFreq_MaxS22 = np.var(pd.to_numeric(dataset['Freq(Hz)S22'].iloc[i-(window_size - 1): i]))\n",
    "        var_MaxS22 = np.var(dataset['S22(DB)'].iloc[i-(window_size - 1): i])\n",
    "        var_S22DEG = np.var(dataset['S22(DEG)'].iloc[i-(window_size - 1): i])\n",
    "\n",
    "\n",
    "        intermediate = pd.DataFrame([meanFreq_MaxS11, mean_MaxS11, mean_S11DEG, meanFreq_MaxS22, mean_MaxS22, \n",
    "                                    mean_S22DEG, varFreq_MaxS11, var_MaxS11, var_S11DEG, varFreq_MaxS22, var_MaxS22, \n",
    "                                    var_S22DEG, weight, cls])\n",
    "        \n",
    "        windowed_dataset = pd.concat([windowed_dataset, intermediate.T], ignore_index=True)\n",
    "\n",
    "        #skip the necessary rows to jump to the next window\n",
    "        for _ in range(step_size - 1):\n",
    "            next(iterator, None)\n",
    "            \n",
    "    windowed_dataset.columns =  ['meanFreq_MaxS11', 'mean_MaxS11', 'mean_S11DEG', 'meanFreq_MaxS22', 'mean_MaxS22', 'mean_S22DEG', \n",
    "                        'varFreq_MaxS11', 'var_MaxS11', 'var_S11DEG', 'varFreq_MaxS22', 'var_MaxS22', 'var_S22DEG',\n",
    "                        'Weight', 'Class']\n",
    "    \n",
    "    return windowed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_plot(df, var1, var2):\n",
    "    x = df[var1]\n",
    "    y = df[var2]\n",
    "    classes = df['Class']\n",
    "\n",
    "    map = {0.0: 'Left', 1.0: 'Centered', 2.0: 'Right'}\n",
    "\n",
    "    # Sostituisci i valori nell'array\n",
    "    array_con_stringhe = np.where(np.isin(classes, list(map.keys())), [map[val] for val in classes], classes)\n",
    "\n",
    "    unique = list(set(array_con_stringhe))\n",
    "    \n",
    "    # Assign colors based on unique values\n",
    "    colors = plt.cm.get_cmap('jet', len(unique))\n",
    "\n",
    "    for i, u in enumerate(unique):\n",
    "        xi = [x[j] for j in range(len(x)) if array_con_stringhe[j] == u]\n",
    "        yi = [y[j] for j in range(len(x)) if array_con_stringhe[j] == u]\n",
    "        plt.scatter(xi, yi, c=[colors(i)], label=str(u))\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "__PREPROCESSING__\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The best results are obtained with smoothing of the signal\n",
    "smoothing = True\n",
    "step_size = 10\n",
    "window_size = 50\n",
    "\n",
    "#only for Lorenzo (the others will skip the default 150)\n",
    "instances_to_skip = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carlotta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_carlotta_path = \"./../Dati/Centered/Carlotta\"\n",
    "c_carlotta = load_data(c_carlotta_path, smoothing_present=smoothing)\n",
    "\n",
    "r_carlotta_path = \"./..//Dati/Right/Carlotta\"\n",
    "r_carlotta = load_data(r_carlotta_path, smoothing_present=smoothing)\n",
    "\n",
    "l_carlotta_path = \"./../Dati/Left/Carlotta\"\n",
    "l_carlotta = load_data(l_carlotta_path, smoothing_present=smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowed_c_carlotta = calculate_window_information(dataset=c_carlotta, window_size=window_size, step_size=step_size, weight=70, cls=1)\n",
    "print(windowed_c_carlotta.shape)\n",
    "\n",
    "windowed_r_carlotta = calculate_window_information(dataset=r_carlotta, window_size=window_size, step_size=step_size, weight=70, cls=2)\n",
    "print(windowed_r_carlotta.shape)\n",
    "\n",
    "windowed_l_carlotta = calculate_window_information(dataset=l_carlotta, window_size=window_size, step_size=step_size, weight=70, cls=0)\n",
    "print(windowed_l_carlotta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carlotta = pd.concat([windowed_l_carlotta, windowed_c_carlotta, windowed_r_carlotta], ignore_index=True)\n",
    "carlotta['Tester'] = 'Carlotta'\n",
    "carlotta['Class'] = carlotta['Class'].astype(int)\n",
    "print(carlotta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = \"./../Dati_unificati/carlotta_smooth.csv\"\n",
    "carlotta.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(f\"Data has been exported to {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_leo_path = \"./../Dati/Centered/Leo\"\n",
    "c_leo = load_data(c_leo_path, smoothing_present=smoothing)\n",
    "\n",
    "r_leo_path = \"./../Dati/Right/Leo\"\n",
    "r_leo = load_data(r_leo_path, smoothing_present=smoothing)\n",
    "\n",
    "l_leo_path = \"./../Dati/Left/Leo\"\n",
    "l_leo = load_data(l_leo_path, smoothing_present=smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowed_c_leo = calculate_window_information(dataset=c_leo, window_size=window_size, step_size=step_size, weight=80, cls=1)\n",
    "print(windowed_c_leo.shape)\n",
    "\n",
    "windowed_r_leo = calculate_window_information(dataset=r_leo, window_size=window_size, step_size=step_size, weight=80, cls=2)\n",
    "print(windowed_r_leo.shape)\n",
    "\n",
    "windowed_l_leo = calculate_window_information(dataset=l_leo, window_size=window_size, step_size=step_size, weight=80, cls=0)\n",
    "print(windowed_l_leo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leo = pd.concat([windowed_l_leo, windowed_c_leo, windowed_r_leo], ignore_index=True)\n",
    "leo['Tester'] = 'Leo'\n",
    "leo['Class'] = leo['Class'].astype(int)\n",
    "print(leo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = \"./../Dati_unificati/leo_smooth.csv\"\n",
    "leo.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(f\"Data has been exported to {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lorenzo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_lorenzo_path = \"./../Dati/Centered/Lorenzo\"\n",
    "c_lorenzo = load_data(c_lorenzo_path, smoothing_present=smoothing)\n",
    "\n",
    "r_lorenzo_path = \"./../Dati/Right/Lorenzo\"\n",
    "r_lorenzo = load_data(r_lorenzo_path, smoothing_present=smoothing)\n",
    "\n",
    "l_lorenzo_path = \"./../Dati/Left/Lorenzo\"\n",
    "l_lorenzo = load_data(l_lorenzo_path, smoothing_present=smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowed_c_lorenzo = calculate_window_information(dataset=c_lorenzo, window_size=window_size, step_size=step_size, weight=90, cls=1, instances_to_skip=instances_to_skip)\n",
    "print(windowed_c_lorenzo.shape)\n",
    "\n",
    "windowed_r_lorenzo = calculate_window_information(dataset=r_lorenzo, window_size=window_size, step_size=step_size, weight=90, cls=2, instances_to_skip=instances_to_skip)\n",
    "print(windowed_r_lorenzo.shape)\n",
    "\n",
    "windowed_l_lorenzo = calculate_window_information(dataset=l_lorenzo, window_size=window_size, step_size=step_size, weight=90, cls=0, instances_to_skip=instances_to_skip)\n",
    "print(windowed_l_lorenzo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lorenzo = pd.concat([windowed_l_lorenzo, windowed_c_lorenzo, windowed_r_lorenzo], ignore_index=True)\n",
    "lorenzo['Tester'] = 'Lorenzo'\n",
    "lorenzo['Class'] = lorenzo['Class'].astype(int)\n",
    "print(lorenzo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = \"./../Dati_unificati/lorenzo_smooth.csv\"\n",
    "lorenzo.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(f\"Data has been exported to {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Irene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_irene_path = \"./../Dati/Centered/Irene\"\n",
    "c_irene = load_data(c_irene_path, smoothing_present=smoothing)\n",
    "\n",
    "r_irene_path = \"./../Dati/Right/Irene\"\n",
    "r_irene = load_data(r_irene_path, smoothing_present=smoothing)\n",
    "\n",
    "l_irene_path = \"./../Dati/Left/Irene\"\n",
    "l_irene = load_data(l_irene_path, smoothing_present=smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowed_c_irene = calculate_window_information(dataset=c_irene, window_size=window_size, step_size=step_size, weight=60, cls=1)\n",
    "print(windowed_c_irene.shape)\n",
    "\n",
    "windowed_r_irene = calculate_window_information(dataset=r_irene, window_size=window_size, step_size=step_size, weight=60, cls=2)\n",
    "print(windowed_r_irene.shape)\n",
    "\n",
    "windowed_l_irene = calculate_window_information(dataset=l_irene, window_size=window_size, step_size=step_size, weight=60, cls=0)\n",
    "print(windowed_l_irene.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irene = pd.concat([windowed_l_irene, windowed_c_irene, windowed_r_irene], ignore_index=True)\n",
    "irene['Tester'] = 'Irene'\n",
    "print(irene.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = \"./../Dati_unificati/irene_smooth.csv\"\n",
    "irene.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(f\"Data has been exported to {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "_Graphs_\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a complete dataset if needed\n",
    "complete_dataset = pd.concat([irene, carlotta, leo, lorenzo], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of possible variables:\n",
    "\n",
    "#'meanFreq_MaxS11', 'mean_MaxS11', 'mean_S11DEG', 'meanFreq_MaxS22', 'mean_MaxS22', 'mean_S22DEG', \n",
    "#'varFreq_MaxS11', 'var_MaxS11', 'var_S11DEG', 'varFreq_MaxS22', 'var_MaxS22', 'var_S22DEG',\n",
    "#'Weight', 'Class'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_exclude = [\"Tester\"] #remove, if needed, some columns from the plot\n",
    "dataset_to_plot = carlotta  #insert the dataset to plot\n",
    "\n",
    "columns_to_plot = [col for col in dataset_to_plot.columns if col not in columns_to_exclude]\n",
    "\n",
    "for i, col in enumerate(columns_to_plot):\n",
    "    sns.boxplot(x=pd.to_numeric(dataset_to_plot[col]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean_MaxS22\n",
    "sns.boxplot(x=pd.to_numeric(carlotta['var_MaxS22']))\n",
    "plt.show()\n",
    "sns.boxplot(x=pd.to_numeric(leo['var_MaxS22']))\n",
    "plt.show()\n",
    "sns.boxplot(x=pd.to_numeric(lorenzo['var_MaxS22']))\n",
    "plt.show()\n",
    "sns.boxplot(x=pd.to_numeric(irene['var_MaxS22']))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_to_plot = complete_dataset  #insert the dataset to plot\n",
    "scatter_matrix(dataset_to_plot, figsize = (16,16),alpha = 1,diagonal = 'hist',c = dataset_to_plot['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert the variables to plot\n",
    "var1 = 'meanFreq_MaxS11'\n",
    "var2 = 'mean_S11DEG'\n",
    "\n",
    "\n",
    "scatter_plot(carlotta, var1, var2)\n",
    "scatter_plot(leo, var1, var2)\n",
    "scatter_plot(irene, var1, var2)\n",
    "scatter_plot(lorenzo, var1, var2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
